{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6244096,"sourceType":"datasetVersion","datasetId":3587878}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\n# Set the paths to your training and testing image folders\ntrain_data_dir = '/kaggle/input/defungi-microscopic-fungi-image/train'\ntest_data_dir = '/kaggle/input/defungi-microscopic-fungi-image/test'\n\n# Set the number of classes and the input size for the EfficientNet model\nnum_classes = 5\ninput_size =150\n\n# Preprocess and augment the images\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and preprocess training images\ntrain_images = []\ntrain_labels = []\n\nfor class_name in os.listdir(train_data_dir):\n    class_dir = os.path.join(train_data_dir, class_name)\n    for image_name in os.listdir(class_dir):\n        image_path = os.path.join(class_dir, image_name)\n        image = cv2.imread(image_path)\n        image = cv2.resize(image, (input_size, input_size))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        train_images.append(image)\n        train_labels.append(class_name)\n\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\n\n# Split the data into training and validation sets\ntrain_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n\n# Load and preprocess testing images\ntest_images = []\ntest_labels = []\n\nfor class_name in os.listdir(test_data_dir):\n    class_dir = os.path.join(test_data_dir, class_name)\n    for image_name in os.listdir(class_dir):\n        image_path = os.path.join(class_dir, image_name)\n        image = cv2.imread(image_path)\n        image = cv2.resize(image, (input_size, input_size))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        test_images.append(image)\n        test_labels.append(class_name)\n\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\n\n# Load the EfficientNet model with pre-trained weights\nbase_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(input_size, input_size, 3))\n\n# Extract features using EfficientNet model\ntrain_features = base_model.predict(train_images)\nval_features = base_model.predict(val_images)\ntest_features = base_model.predict(test_images)\n\n# Flatten the features\ntrain_features = train_features.reshape(train_features.shape[0], -1)\nval_features = val_features.reshape(val_features.shape[0], -1)\ntest_features = test_features.reshape(test_features.shape[0], -1)\n\n# Convert labels to strings\n# train_labels = train_labels.astype(str)\n# val_labels = val_labels.astype(str)\n# test_labels = test_labels.astype(str)\n\n# Convert labels to integers\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_labels)\nval_labels = label_encoder.transform(val_labels)\ntest_labels = label_encoder.transform(test_labels)\n\nclassifiers = [\n    XGBClassifier(),\n    AdaBoostClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    SVC(),\n    LogisticRegression(),\n    GaussianNB()\n]\n\nfor classifier in classifiers:\n  classifier.fit(train_features, train_labels)\n    # train_predictions = classifier.predict(train_features)\n    # test_predictions = classifier.predict(test_features)\n  print('Classifier:', classifier.__class__.__name__)\n  classifier.fit(train_features, train_labels)\n\n      # Make predictions on validation and testing set\n  train_predictions = classifier.predict(train_features)\n  val_predictions = classifier.predict(val_features)\n  test_predictions = classifier.predict(test_features)\n\n      # Calculate accuracy\n  val_accuracy = accuracy_score(val_labels, val_predictions)\n  test_accuracy = accuracy_score(test_labels, test_predictions)\n      # Calculate training accuracy\n  train_accuracy = accuracy_score(train_labels, train_predictions)\n\n      # Print training accuracy\n  print(\"Training Accuracy:\", train_accuracy)\n      # Print accuracy, classification report, and confusion matrix\n  print(\"Validation Accuracy:\", val_accuracy)\n  print(\"Test Accuracy:\", test_accuracy)\n  print(\"Classification Report (Validation Set):\")\n  print(classification_report(val_labels, val_predictions))\n  print(\"Classification Report (Test Set):\")\n  print(classification_report(test_labels, test_predictions))\n      # Print classification report (training set)\n  print(\"Classification Report (Training Set):\")\n  print(classification_report(train_labels, train_predictions))\n  print(\"Confusion Matrix (Validation Set):\")\n  print(confusion_matrix(val_labels, val_predictions))\n  print(\"Confusion Matrix (Test Set):\")\n  print(confusion_matrix(test_labels, test_predictions))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-26T06:12:59.744000Z","iopub.execute_input":"2023-12-26T06:12:59.744348Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n43941136/43941136 [==============================] - 0s 0us/step\n183/183 [==============================] - 22s 53ms/step\n46/46 [==============================] - 3s 67ms/step\n57/57 [==============================] - 4s 65ms/step\nClassifier: XGBClassifier\nTraining Accuracy: 1.0\nValidation Accuracy: 0.7333790267306374\nTest Accuracy: 0.7218869994514536\nClassification Report (Validation Set):\n              precision    recall  f1-score   support\n\n           0       0.67      0.44      0.53       401\n           1       0.72      0.92      0.81       692\n           2       0.88      0.74      0.80       108\n           3       0.81      0.77      0.79       128\n           4       0.77      0.58      0.66       130\n\n    accuracy                           0.73      1459\n   macro avg       0.77      0.69      0.72      1459\nweighted avg       0.73      0.73      0.72      1459\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n           0       0.55      0.39      0.46       467\n           1       0.73      0.91      0.81       881\n           2       0.88      0.76      0.81       148\n           3       0.81      0.72      0.76       163\n           4       0.82      0.63      0.71       164\n\n    accuracy                           0.72      1823\n   macro avg       0.76      0.68      0.71      1823\nweighted avg       0.71      0.72      0.71      1823\n\nClassification Report (Training Set):\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      1466\n           1       1.00      1.00      1.00      2831\n           2       1.00      1.00      1.00       483\n           3       1.00      1.00      1.00       527\n           4       1.00      1.00      1.00       525\n\n    accuracy                           1.00      5832\n   macro avg       1.00      1.00      1.00      5832\nweighted avg       1.00      1.00      1.00      5832\n\nConfusion Matrix (Validation Set):\n[[178 199   1  10  13]\n [ 47 638   2   1   4]\n [  6  13  80   5   4]\n [  9  14   5  99   1]\n [ 26  19   3   7  75]]\nConfusion Matrix (Test Set):\n[[182 248   6  16  15]\n [ 70 801   1   4   5]\n [ 17  15 112   3   1]\n [ 27  11   6 117   2]\n [ 33  20   2   5 104]]\nClassifier: AdaBoostClassifier\nTraining Accuracy: 0.6284293552812071\nValidation Accuracy: 0.6038382453735435\nTest Accuracy: 0.5973669775095996\nClassification Report (Validation Set):\n              precision    recall  f1-score   support\n\n           0       0.46      0.21      0.29       401\n           1       0.65      0.86      0.74       692\n           2       0.59      0.58      0.59       108\n           3       0.58      0.61      0.59       128\n           4       0.50      0.45      0.48       130\n\n    accuracy                           0.60      1459\n   macro avg       0.56      0.54      0.54      1459\nweighted avg       0.57      0.60      0.57      1459\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n           0       0.35      0.17      0.23       467\n           1       0.66      0.85      0.74       881\n           2       0.57      0.51      0.54       148\n           3       0.59      0.64      0.62       163\n           4       0.55      0.49      0.52       164\n\n    accuracy                           0.60      1823\n   macro avg       0.54      0.53      0.53      1823\nweighted avg       0.56      0.60      0.56      1823\n\nClassification Report (Training Set):\n              precision    recall  f1-score   support\n\n           0       0.39      0.20      0.26      1466\n           1       0.67      0.87      0.76      2831\n           2       0.68      0.61      0.64       483\n           3       0.67      0.68      0.67       527\n           4       0.59      0.48      0.53       525\n\n    accuracy                           0.63      5832\n   macro avg       0.60      0.57      0.57      5832\nweighted avg       0.59      0.63      0.60      5832\n\nConfusion Matrix (Validation Set):\n[[ 85 250  15  23  28]\n [ 59 596   7   8  22]\n [ 10  15  63  15   5]\n [ 17  13  17  78   3]\n [ 14  41   5  11  59]]\nConfusion Matrix (Test Set):\n[[ 81 307  23  23  33]\n [ 88 747   7  10  29]\n [ 22  17  76  32   1]\n [ 22  17  17 105   2]\n [ 20  47  10   7  80]]\n","output_type":"stream"}]}]}